name: Run Python Scraper

# This controls when the action runs
on:
  schedule:
    # Runs at 08:00 UTC on the 1st day of every month
    # You can change this. '0 8 * * *' would run daily at 8:00
    - cron: '0 8 1 * *' 

  # This adds a manual "Run workflow" button
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      # Step 1: Checks out your repository code
      - name: Check out repository
        uses: actions/checkout@v4

      # Step 2: Sets up Python
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10' 

      # Step 3: Installs all your libraries
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install gspread gspread-dataframe pandas beautifulsoup4 requests

      # Step 4: Creates the credentials file from your GitHub Secret
      - name: Create credentials file
        run: |
          echo "${{ secrets.GSPREAD_CREDS }}" > service_account_creds.json

      # Step 5: Runs your script
      - name: Run scraper
        run: |
          python scraper.py
